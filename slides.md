## Improve Security in the Virtual Machine Hypervisor
#### SR - Seminar

<small><a href="http://lucar.in">Luca Rinaldi</a></small>



## Agenda
- Intro to VM hypervisors

- NoHype: removing the hypervisor

- NOVA: minimizing the hypervisor

- Conclusions



## Hypervisor
It **emulates** a given hardware and permitting to the guest OS to run directly on it.

It usually needs a large and complex piece of code and frequent interactions with the guest OS.

A **VM exits** are generated by the vCPU when any operation performed by the guest OS needs the intervention of the hypervisor.




## Security thread in virtualisation
Hypervisors should maintain VM-VM and VM-host isolation.

There are cases in which, through hypervisor vulnerabilities, an attacker can exit the virtual machine.

Usually hypervisors have a large TCB.


## VM escape vulnerabilities
<div style="font-size: 28px;">

- CVE-2007-1744: Directory traversal vulnerability in shared folders feature
- CVE-2008-0923: Path traversal vulnerability in VMware’s shared folders implementation
- CVE-2009-1244: Cloudburst (VMware virtual video adapter vulnerability)
- CVE-2011-1751: Missing hotplug check during device removal
- CVE-2012-0217: 64-bit PV guest privilege escalation vulnerability
- CVE-2014-0983: Oracle VirtualBox 3D acceleration multiple memory corruption vulnerabilities
- VENOM (CVE-2015-3456) is unique in that it applies to a wide array of virtualization platforms, works on default configurations, and allows for direct arbitrary code execution.



## NoHype
It eliminates the whole hypervisor and its attack surface.

It removes the need for VMs to constantly interact with the hypervisor during their lifetime.



## Main Design
- Pre-allocating Memory and Cores

- Using only Virtualised I/O Devices

- Short-Circuiting the System Discovery

- Avoiding Indirection



## Pre-allocating Memory and Cores
Without hypervisor it is not possible to dynamically allocate memory and computational resources.

It fix the memory allocation and the cores before the VM starts.



## Using only Virtualised I/O Devices
Without hypervisor it is not possible to emulate I/O devices.

It can use dedicated I/O devices or devices with virtualisation technology.

The only true indispensable I/O device in the cloud is the NIC card because the storage device can be accessed through the network.



## Short-Circuiting System Discovery
The guest OS do not run discovery calls on the hardware at runtime, because there is no hypervisor to answer them.

Gust OS kernel is modified, so that those operations are executed only at boot time and the answer is cached.



## Avoiding Indirection
The hypervisors use indirection to modify the processor IDs inside the guest OS so that they start from 0.

With noHype and static allocation of VMs to core, each VM can access the correct processor and avoids indirection.

For the same reason re-route of the interrupts is removed.



## Prototype Design
![img](img/NoHype-four_stage.png)

Hypervisor: *Xen 4.0*, Guest OS: *Linux 2.6.35.4*, CPU: *Intel XEON W5580*, NIC card controller: *Intel 82576*


## VM Creation
The Xen hypervisor manages VM initialisation:

- it sets core affinity

- it sets the NIC by a PCI pass through

- it sets memory allocation using VT-d


## VM Bootup
These are the main phases:

- load the kernel and the initial RAM disk using the network

- run the modified Linux kernel

- disengage the hypervisor

- mount the iSCSI HD drive

- exec user code

note:
iSCSI: Internet Small Computer Systems Interface, an Internet Protocol (IP)-based storage networking standard for linking data storage facilities. In a nutshell, it provides block-level access to storage devices over a TCP/IP network.


## VM Shutdown
VM controller structure (VMCS) of the CPU is configured so to exit the VM mode when NMI interruptions are received.

This gives the possibility to the VM to handle the exit signal, so that the VM can shutdown correctly.



## Problems of this approach
<div style="font-size: 25px;">

- Static allocation of the resources. <!-- .element: class="fragment" -->

- Changes of existing hardware and virtualisation stack. <!-- .element: class="fragment" -->

- The virtualisation layer could no longer be used for VMs interposition. <!-- .element: class="fragment" -->

- Trust is still in the hypervisor. <!-- .element: class="fragment" -->

- It only considers software attacks and cannot guard against wore complex attack (inspecting a VM disk, bus snooping and memory freezing). <!-- .element: class="fragment" -->

- Modified Kernel on the Guest can introduce incompatibility with user software or new vulnerabilities. <!-- .element: class="fragment" -->

- Without indirection guest can easily know to be inside a VM. <!-- .element: class="fragment" -->

note:
On the software side, NoHype [21, 22] advocates space-partitioning cores, memory and devices to a VM, detaching the virtualization layer during a VM’s normal execution time. This reduces the attack surfaces for a VM as the VM is physically isolated from other VMs as well as the management VM for most of the time. Compared to NoHype, HyperCoffer assumes a stronger adversary model that further considers physical attacks, while NoHype only considers software attacks and cannot guard against sophisticated attacks such as inspecting a VM disk, bus snooping and memory freezing. Further, HyperCoffer still retains most functionalities in a commercial hypervisor like time-multiplexing resources, which are currently absent in NoHype.

NoHype [31] tries to address the trustworthiness of multi-tenant
clouds by removing the virtualization layer during execution. However,
removing the virtualization layer may also lose some useful
features such as sharing resources across multiple VMs, which are
key features of multi-tenant clouds. Further, NoHype still trusts the
VM management software and requires changes to existing hardware
and virtualization stack and there is no available implementation
of such a system.

NoHype [23] advocates removing the hypervisor altogether, using
static partitioning of CPUs, memory, and peripherals among VMs.
This would allow a host to be shared by multiple operating systems,
but with none of the other benefits of virtualization. In particular, the
virtualization layer could no longer be used for interposition, which
is necessary for live migration [13], memory sharing and compression
[19, 32], and security enhancements [11, 30, 46, 16].



## NOVA
It is a micro-hypervisor that minimizes the amount of code in the privileged hypervisor.

The main features are:

- virtualisation at user level.

- VM's TCB reduction by one order of magnitude.


## Lines of code
![img](img/NOVA-graph.png)



## Design
![img](img/NOVA-architecture.png)

Least privilege among the components.



## Micro-hypervisor
It implements a capability-based hypercall interface

**Capabilities** are opaque and immutable to the user, they cannot be inspected, modified, or addressed directly.

It is possible to **delegate** copies of a capability with the same or reduced permissions to other domains that require access to the object.

note:
The use of capabilities leads to fine-grained access control.


## Micro-hypervisor objects
The main features of the kernel are implemented by means of:

- Protection domains

- Execution contexts

- Scheduling contexts

- Portals

- Semaphores

note:
- **protection domains**: it is a resource container that implement spatial isolation, and abstract the different between a VM and a user application.

- **execution contexts**: are the activities inside a protection domain, and they abstract between thread and virtual CPU.  They can execute program code, manipulate data, and use portals to send messages to other execution contexts.

- **scheduling contexts**:  it couple a time quantum with a priority and ensure that no execution context can monopolize the CPU.

- **portals**: are used to communicate between protected domain, ensuring a cross domain channel.

- **semaphores**: facilitate the synchronization between execution context on the same or different process. The hypervisor use it to signal the occurrence of hardware interruption.



## Root Partition Manager
It manages all the memory regions, I/O ports, and interrupts of the system.

It is the first protected domain created by the micro-hypervisor after boot and it can create and delegate new protected domains to assign resources.



## Virtual Machine Monitor
It supports the execution of an unmodified guest OS in the VM, emulating sensitive instructions and providing virtual devices.

It runs as a user-level application and there is one for each VM.



## Problem of the NOVA approach
<div style="font-size: 26px;">

- No rich set of features for deployment in commercial hosting environments. <!-- .element: class="fragment" -->

- They had to remove hardware supports to achieve the reduction of the TCB. <!-- .element: class="fragment" -->

- Assumption that an attacker cannot violate the booting sequence. <!-- .element: class="fragment" -->

- The micro-hypervisor is still in charge of complex management duties. (like address space management, interrupt and exception handling, and communication between the running workloads). <!-- .element: class="fragment" -->
<!--TODO: controllare questa affermazione!-->

- Reduction of the hypervisor LOCs does not imply that formal verification methods can apply. <!-- .element: class="fragment" -->

- The use of a VMM for each VM reduces the risk of damaging other VMs but does not reduce the possibility to attack the hypervisor kernel. <!-- .element: class="fragment" -->

note:
NOVA [60] is micro-kernel based VMM that decouples the traditional monolithic VMM into a component-based system, and improves security by introducing capability-based access control for different components in a VMM. The security of the management software in However, these systems aim at protecting the virtualization layer from external attacks to the VM stack, but without considering possible attacks that leverage legal maintenance operations from the cloud operators, which is a new requirement in multi-tenant cloud.

However, these approaches mostly only protect
VMMs from attacks from a malicious guest VM, without consider
ation of preventing an operator with control of management tools
and control VM from tampering with or stealing users’ confidential
data, especially external storage such as virtual disks. Further, they
require changes to the core parts of a VMM [68] or even a complete
reconstruction of VMMs [31, 60], thus may pose a notable

For example, they cannot defend against attacks leveraging
legal maintenance operations such as dump/clone/migrate a VM or
virtual disks. Further, they require a reconstruction of the cloud
software stack. To this end, it is critical to provide multi-tenant
cloud with an approach that defending against attackers penetrated
through the three attack surfaces from tampering with tenant VMs,
yet with a small trusted computing base, which motivates the design
and implementation of CloudVisor.

In this vein, from-scratch
hypervisors [38, 40, 42] have shown that particular security properties
can be achieved by rearchitecting the platform, but they do not
provide the rich set of features necessary for deployment in commercial hosting environments.

More recently, NOVA [42]
uses a similar architecture and explicitly partitions the TCB into
several user-level processes within the hypervisor. Although capable
of running multiple unmodified OSes concurrently, the removal
of the control VM and requirement for NOVA-specific drivers sacrifice
hardware support for TCB size. Also, it is far from complete:
it cannot run Windows guests and has limited toolstack support.

To our knowledge, most of the other SRTM-based
approaches assume that the attacker is unable to violate the
integrity of the booting process (e.g. NOVA [35] explicitly
claims so). However, the boot chain nowadays can be com-
plex and repetitive. For example, GRUB 2 [14] nowadays
contains ∼200K LOCs in total and even GRUB Legacy con-
tains ∼10K LOCs as its core components. Some of the ini-
tialization duties of the bootloader have already be carried
out by the BIOS and will later be covered again by the
VMM. It can largely decrease the TCB size if we merge
them together into the BIOS and remove unnecessary boot
procedures.

There are some approaches directly dividing VMM into
separated components with different privileges. NOVA [35]
constructs a microkernel-based VMM that is ∼9K LOCs in
size. Despite its thin TCB compared to commodity hypervi-
sors, the complexity of TCB is not markedly decreased since
the microhypervisor is still in charge of complex manage-
ment duties like address space management, interrupt and
exception handling, and communication between the run-
ning workloads. So the thin TCB is still difficult to be se-
cured and verified dynamically. Although seL4 [21] pro-
poses a technique to formally verify a microkernel with
∼8.7K LOCs, it imposes several restrictions on the micro-
kernel functionality. Thus a verifiable microhypervisor re-
mains impractical so far. Other than microkernel-based sys-
tems, VMM Disaggregation [30] also shrinks the TCB size
by moving some VMM components out of the privileged do-
main. However, the TCB size is still too large for dynamic
protection.



## Conclusions
VMs are fundamental in the Cloud scenario and guaranteeing their security is very important.

Hypervisors have to improve their security and reliability.

Being too drastic and requiring considerable "re-design" of the infrastructure nor NOVA NoHype approaches can be use in real application.



## References
<div style="font-size: 24px;">

- Szefer, J., Keller, E., Lee, R. B., & Rexford, J. (2011, October). **Eliminating the hypervisor attack surface for a more secure cloud.** In Proceedings of the 18th ACM conference on Computer and communications security (pp. 401-412). ACM.

- Steinberg, U., & Kauer, B. (2010, April). **NOVA: a microhypervisor-based secure virtualization architecture.** In Proceedings of the 5th European conference on Computer systems (pp. 209-222). ACM.

- Zhang, Y., Pan, W., Wang, Q., Bai, K., & Yu, M. (2012). **HypeBIOS: Enforcing VM Isolation with Minimized and Decomposed Cloud TCB.** Virginia Commonwealth University, Technical report.

- Zhang, F., Chen, J., Chen, H., & Zang, B. (2011, October). **CloudVisor: retrofitting protection of virtual machines in multi-tenant cloud with nested virtualization.** In Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles (pp. 203-216). ACM.

- Jason Geffner, CrowdStrike Senior Security Researcher (2015-05-21) **VENOM Vulnerability**, Available at: http://venom.crowdstrike.com/ (Accessed: 2016, October).
